{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b47b15de-64a5-4fa9-a688-23d3efa9a2f4",
    "_uuid": "0cc385a7-98f6-4883-96eb-7b89c7c9aa1c",
    "papermill": {
     "duration": 0.016533,
     "end_time": "2022-04-12T14:48:23.471825",
     "exception": false,
     "start_time": "2022-04-12T14:48:23.455292",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"width:100%; height:140px\">\n",
    "    <img src=\"https://www.kuleuven.be/internationaal/thinktank/fotos-en-logos/ku-leuven-logo.png/image_preview\" width = 300px, heigh = auto align=left>\n",
    "</div>\n",
    "\n",
    "\n",
    "KUL H02A5a Computer Vision: Group Assignment 2\n",
    "---------------------------------------------------------------\n",
    "Student numbers: <span style=\"color:red\">r0703889, r0909802, r0716758, r0916443, r0822692</span>. \n",
    "\n",
    "In this group assignment your team will delve into some deep learning applications for computer vision. The assignment will be delivered in the same groups from *Group assignment 1* and you start from this template notebook. The notebook you submit for grading is the last notebook you submit in the [Kaggle competition](https://www.kaggle.com/t/d11be6a431b84198bc85f54ae7e2563f) prior to the deadline on **Tuesday 24 May 23:59**. Closely follow [these instructions](https://github.com/gourie/kaggle_inclass) for joining the competition, sharing your notebook with the TAs and making a valid notebook submission to the competition. A notebook submission not only produces a *submission.csv* file that is used to calculate your competition score, it also runs the entire notebook and saves its output as if it were a report. This way it becomes an all-in-one-place document for the TAs to review. As such, please make sure that your final submission notebook is self-contained and fully documented (e.g. provide strong arguments for the design choices that you make). Most likely, this notebook format is not appropriate to run all your experiments at submission time (e.g. the training of CNNs is a memory hungry and time consuming process; due to limited Kaggle resources). It can be a good idea to distribute your code otherwise and only summarize your findings, together with your final predictions, in the submission notebook. For example, you can substitute experiments with some text and figures that you have produced \"offline\" (e.g. learning curves and results on your internal validation set or even the test set for different architectures, pre-processing pipelines, etc). We advise you to first go through the PDF of this assignment entirely before you really start. Then, it can be a good idea to go through this notebook and use it as your first notebook submission to the competition. You can make use of the *Group assignment 2* forum/discussion board on Toledo if you have any questions. Good luck and have fun!\n",
    "\n",
    "---------------------------------------------------------------\n",
    "NOTES:\n",
    "* This notebook is just a template. Please keep the five main sections, but feel free to adjust further in any way you please!\n",
    "* Clearly indicate the improvements that you make! You can for instance use subsections like: *3.1. Improvement: applying loss function f instead of g*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "35358cfb-b13d-4277-8dd5-4e663c8cd775",
    "_uuid": "3b40b846-d7da-46d8-b354-c6d5c5ded56e",
    "papermill": {
     "duration": 0.014397,
     "end_time": "2022-04-12T14:48:23.501501",
     "exception": false,
     "start_time": "2022-04-12T14:48:23.487104",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Overview\n",
    "This assignment consists of *three main parts* for which we expect you to provide code and extensive documentation in the notebook:\n",
    "* Image classification (Sect. 2)\n",
    "* Semantic segmentation (Sect. 3)\n",
    "* Adversarial attacks (Sect. 4)\n",
    "\n",
    "In the first part, you will train an end-to-end neural network for image classification. In the second part, you will do the same for semantic segmentation. For these two tasks we expect you to put a significant effort into optimizing performance and as such competing with fellow students via the Kaggle competition. In the third part, you will try to find and exploit the weaknesses of your classification and/or segmentation network. For the latter there is no competition format, but we do expect you to put significant effort in achieving good performance on the self-posed goal for that part. Finally, we ask you to reflect and produce an overall discussion with links to the lectures and \"real world\" computer vision (Sect. 5). It is important to note that only a small part of the grade will reflect the actual performance of your networks. However, we do expect all things to work! In general, we will evaluate the correctness of your approach and your understanding of what you have done that you demonstrate in the descriptions and discussions in the final notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014263,
     "end_time": "2022-04-12T14:48:23.530341",
     "exception": false,
     "start_time": "2022-04-12T14:48:23.516078",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.1 Deep learning resources\n",
    "If you did not yet explore this in *Group assignment 1 (Sect. 2)*, we recommend using the TensorFlow and/or Keras library for building deep learning models. You can find a nice crash course [here](https://colab.research.google.com/drive/1UCJt8EYjlzCs1H1d1X0iDGYJsHKwu-NO)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "7ddf657a-b938-4a49-87dc-b0db9af9156d",
    "_uuid": "c65ea4f1-cc90-408f-b8e0-7c7399ec7e21",
    "execution": {
     "iopub.execute_input": "2022-05-17T15:21:13.489229Z",
     "iopub.status.busy": "2022-05-17T15:21:13.488933Z",
     "iopub.status.idle": "2022-05-17T15:21:13.494755Z",
     "shell.execute_reply": "2022-05-17T15:21:13.493792Z",
     "shell.execute_reply.started": "2022-05-17T15:21:13.489198Z"
    },
    "papermill": {
     "duration": 5.416492,
     "end_time": "2022-04-12T14:48:28.96151",
     "exception": false,
     "start_time": "2022-04-12T14:48:23.545018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014416,
     "end_time": "2022-04-12T14:48:28.990998",
     "exception": false,
     "start_time": "2022-04-12T14:48:28.976582",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.2 PASCAL VOC 2009\n",
    "For this project you will be using the [PASCAL VOC 2009](http://host.robots.ox.ac.uk/pascal/VOC/voc2009/index.html) dataset. This dataset consists of colour images of various scenes with different object classes (e.g. animal: *bird, cat, ...*; vehicle: *aeroplane, bicycle, ...*), totalling 20 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "1ce67f49-6bf6-4e5c-b5e4-576e893616a9",
    "_uuid": "3b1c5fbb-757f-4349-b224-e281c540e1ad",
    "execution": {
     "iopub.execute_input": "2022-05-17T15:21:16.300095Z",
     "iopub.status.busy": "2022-05-17T15:21:16.299316Z",
     "iopub.status.idle": "2022-05-17T15:21:27.146463Z",
     "shell.execute_reply": "2022-05-17T15:21:27.145699Z",
     "shell.execute_reply.started": "2022-05-17T15:21:16.300053Z"
    },
    "papermill": {
     "duration": 21.336481,
     "end_time": "2022-04-12T14:48:50.342062",
     "exception": false,
     "start_time": "2022-04-12T14:48:29.005581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/kul-h02a5a-computer-vision-ga2-2022/train/train_set.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12188\\2555228015.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Loading the training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/kaggle/input/kul-h02a5a-computer-vision-ga2-2022/train/train_set.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Id\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"img\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/kaggle/input/kul-h02a5a-computer-vision-ga2-2022/train/img/train_{}.npy'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"seg\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/kaggle/input/kul-h02a5a-computer-vision-ga2-2022/train/seg/train_{}.npy'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.julia\\conda\\3\\envs\\CV\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.julia\\conda\\3\\envs\\CV\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.julia\\conda\\3\\envs\\CV\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.julia\\conda\\3\\envs\\CV\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.julia\\conda\\3\\envs\\CV\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.julia\\conda\\3\\envs\\CV\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.julia\\conda\\3\\envs\\CV\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"encoding_errors\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"strict\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m         )\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.julia\\conda\\3\\envs\\CV\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m             )\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/kul-h02a5a-computer-vision-ga2-2022/train/train_set.csv'"
     ]
    }
   ],
   "source": [
    "# Loading the training data\n",
    "train_df = pd.read_csv('/kaggle/input/kul-h02a5a-computer-vision-ga2-2022/train/train_set.csv', index_col=\"Id\")\n",
    "labels = train_df.columns\n",
    "train_df[\"img\"] = [np.load('/kaggle/input/kul-h02a5a-computer-vision-ga2-2022/train/img/train_{}.npy'.format(idx)) for idx, _ in train_df.iterrows()]\n",
    "train_df[\"seg\"] = [np.load('/kaggle/input/kul-h02a5a-computer-vision-ga2-2022/train/seg/train_{}.npy'.format(idx)) for idx, _ in train_df.iterrows()]\n",
    "print(\"The training set contains {} examples.\".format(len(train_df)))\n",
    "\n",
    "# Show some examples\n",
    "fig, axs = plt.subplots(2, 20, figsize=(10 * 20, 10 * 2))\n",
    "for i, label in enumerate(labels):\n",
    "    df = train_df.loc[train_df[label] == 1]\n",
    "    axs[0, i].imshow(df.iloc[0][\"img\"], vmin=0, vmax=255)\n",
    "    axs[0, i].set_title(\"\\n\".join(label for label in labels if df.iloc[0][label] == 1), fontsize=40)\n",
    "    axs[0, i].axis(\"off\")\n",
    "    axs[1, i].imshow(df.iloc[0][\"seg\"], vmin=0, vmax=20)  # with the absolute color scale it will be clear that the arrays in the \"seg\" column are label maps (labels in [0, 20])\n",
    "    axs[1, i].axis(\"off\")\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "# The training dataframe contains for each image 20 columns with the ground truth classification labels and 20 column with the ground truth segmentation maps for each class\n",
    "train_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:21:27.150013Z",
     "iopub.status.busy": "2022-05-17T15:21:27.148331Z",
     "iopub.status.idle": "2022-05-17T15:21:30.982584Z",
     "shell.execute_reply": "2022-05-17T15:21:30.981719Z",
     "shell.execute_reply.started": "2022-05-17T15:21:27.149967Z"
    },
    "papermill": {
     "duration": 11.507733,
     "end_time": "2022-04-12T14:49:02.044233",
     "exception": false,
     "start_time": "2022-04-12T14:48:50.5365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading the test data\n",
    "test_df = pd.read_csv('/kaggle/input/kul-h02a5a-computer-vision-ga2-2022/test/test_set.csv', index_col=\"Id\")\n",
    "test_df[\"img\"] = [np.load('/kaggle/input/kul-h02a5a-computer-vision-ga2-2022/test/img/test_{}.npy'.format(idx)) for idx, _ in test_df.iterrows()]\n",
    "test_df[\"seg\"] = [-1 * np.ones(img.shape[:2], dtype=np.int8) for img in test_df[\"img\"]]\n",
    "print(\"The test set contains {} examples.\".format(len(test_df)))\n",
    "\n",
    "# The test dataframe is similar to the training dataframe, but here the values are -1 --> your task is to fill in these as good as possible in Sect. 2 and Sect. 3; in Sect. 6 this dataframe is automatically transformed in the submission CSV!\n",
    "test_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.197841,
     "end_time": "2022-04-12T14:49:02.437252",
     "exception": false,
     "start_time": "2022-04-12T14:49:02.239411",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1.3 Your Kaggle submission\n",
    "Your filled test dataframe (during Sect. 2 and Sect. 3) must be converted to a submission.csv with two rows per example (one for classification and one for segmentation) and with only a single prediction column (the multi-class/label predictions running length encoded). You don't need to edit this section. Just make sure to call this function at the right position in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:21:30.984300Z",
     "iopub.status.busy": "2022-05-17T15:21:30.984035Z",
     "iopub.status.idle": "2022-05-17T15:21:30.994003Z",
     "shell.execute_reply": "2022-05-17T15:21:30.993156Z",
     "shell.execute_reply.started": "2022-05-17T15:21:30.984265Z"
    },
    "papermill": {
     "duration": 0.213344,
     "end_time": "2022-04-12T14:49:02.848597",
     "exception": false,
     "start_time": "2022-04-12T14:49:02.635253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _rle_encode(img):\n",
    "    \"\"\"\n",
    "    Kaggle requires RLE encoded predictions for computation of the Dice score (https://www.kaggle.com/lifa08/run-length-encode-and-decode)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img: np.ndarray - binary img array\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    rle: String - running length encoded version of img\n",
    "    \"\"\"\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    rle = ' '.join(str(x) for x in runs)\n",
    "    return rle\n",
    "\n",
    "def generate_submission(df):\n",
    "    \"\"\"\n",
    "    Make sure to call this function once after you completed Sect. 2 and Sect. 3! It transforms and writes your test dataframe into a submission.csv file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pd.DataFrame - filled dataframe that needs to be converted\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    submission_df: pd.DataFrame - df in submission format.\n",
    "    \"\"\"\n",
    "    df_dict = {\"Id\": [], \"Predicted\": []}\n",
    "    for idx, _ in df.iterrows():\n",
    "        df_dict[\"Id\"].append(f\"{idx}_classification\")\n",
    "        df_dict[\"Predicted\"].append(_rle_encode(np.array(df.loc[idx, labels])))\n",
    "        df_dict[\"Id\"].append(f\"{idx}_segmentation\")\n",
    "        df_dict[\"Predicted\"].append(_rle_encode(np.array([df.loc[idx, \"seg\"] == j + 1 for j in range(len(labels))])))\n",
    "    \n",
    "    submission_df = pd.DataFrame(data=df_dict, dtype=str).set_index(\"Id\")\n",
    "    submission_df.to_csv(\"submission.csv\")\n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: write some explenation about the preprocessing part\n",
    "\n",
    "Balance, resize, normalise, filtering, if necessary converten to gray scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:21:35.656388Z",
     "iopub.status.busy": "2022-05-17T15:21:35.656097Z",
     "iopub.status.idle": "2022-05-17T15:21:35.667514Z",
     "shell.execute_reply": "2022-05-17T15:21:35.666765Z",
     "shell.execute_reply.started": "2022-05-17T15:21:35.656358Z"
    }
   },
   "outputs": [],
   "source": [
    "def augmentData(data):\n",
    "    labels = data.columns\n",
    "    pp = labels.get_loc(\"person\") ##Position person\n",
    "    for i in range(data[\"img\"].shape[0]):\n",
    "        select= data.loc[i]\n",
    "        if select[labels[pp]]==0:\n",
    "        \n",
    "            FLR = select.copy()\n",
    "            FLR[\"img\"] = np.array(tf.image.flip_left_right(FLR[\"img\"]))\n",
    "            FLR[\"seg\"] = np.array(tf.image.flip_left_right(tf.expand_dims(FLR[\"seg\"],axis=2)))\n",
    "            data = data.append(FLR,ignore_index=True)\n",
    "        \n",
    "            FUD = select.copy()\n",
    "            FUD[\"img\"] = np.array(tf.image.flip_up_down(FUD[\"img\"]))\n",
    "            FUD[\"seg\"] = np.array(tf.image.flip_up_down(tf.expand_dims(FUD[\"seg\"],axis=2)))\n",
    "            data = data.append(FUD,ignore_index=True)\n",
    "        \n",
    "            B = select.copy()\n",
    "            B[\"img\"] = np.array(tf.image.random_brightness(B[\"img\"],0.6, seed=None))\n",
    "            data = data.append(B,ignore_index=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:21:37.987814Z",
     "iopub.status.busy": "2022-05-17T15:21:37.987057Z",
     "iopub.status.idle": "2022-05-17T15:21:38.001622Z",
     "shell.execute_reply": "2022-05-17T15:21:38.000739Z",
     "shell.execute_reply.started": "2022-05-17T15:21:37.987775Z"
    }
   },
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    \n",
    "    def __init__(self, img_size, test):\n",
    "        self.img_size = img_size\n",
    "        self.width = self.img_size[1]\n",
    "        self.height = self.img_size[0]\n",
    "        self.test = test\n",
    "        \n",
    "    def resize(self,img):\n",
    "        resized = cv2.resize(img, (self.width,self.height), interpolation = cv2.INTER_AREA)\n",
    "        return resized\n",
    "    \n",
    "    def normalization(self,gray_img):\n",
    "        img = gray_img / 255.0\n",
    "        return img\n",
    "    \n",
    "    def Filter(self,img,filter):\n",
    "        if filter=='Gaussian':\n",
    "            img = cv2.GaussianBlur(img,(5,5),cv2.BORDER_DEFAULT)\n",
    "        elif filter=='Median':\n",
    "            img = cv2.medianBlur(img,5)\n",
    "        else:\n",
    "            raise Error\n",
    "            \n",
    "        return img\n",
    "    \n",
    "    def preprocess(self,data):\n",
    "        preprocData = data.copy()\n",
    "        images = data[\"img\"]\n",
    "        segmentations = data[\"seg\"]\n",
    "        nb_images = images.shape[0]\n",
    "        for i in range(nb_images):\n",
    "            image = images[i]\n",
    "            seg = segmentations[i]\n",
    "            # Resize both img and seg\n",
    "            image = self.resize(image)\n",
    "            if self.test == False:\n",
    "                seg = self.resize(seg)\n",
    "            # Normalization\n",
    "            normalized_img = self.normalization(image)\n",
    "            # Filter \n",
    "            blur_img = self.Filter(normalized_img,'Gaussian')\n",
    "            img = tf.convert_to_tensor(blur_img)\n",
    "            seg = tf.convert_to_tensor(seg)\n",
    "            images[i]=img\n",
    "            segmentations[i]=seg\n",
    "            \n",
    "        preprocData['img'] = images\n",
    "        preprocData['seg'] = segmentations\n",
    "        return preprocData\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        return self.preprocess(data)\n",
    "        \n",
    "\n",
    "def FindLargestDim(data):\n",
    "    imgs = data['img']\n",
    "    x_max = 0\n",
    "    y_max = 0\n",
    "    for img in imgs:\n",
    "        x,y,_ = img.shape\n",
    "        if x>x_max:\n",
    "            x_max=x\n",
    "        if y>y_max:\n",
    "            y_max=y\n",
    "    return (x_max,y_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:21:43.408119Z",
     "iopub.status.busy": "2022-05-17T15:21:43.407377Z",
     "iopub.status.idle": "2022-05-17T15:21:59.894171Z",
     "shell.execute_reply": "2022-05-17T15:21:59.893313Z",
     "shell.execute_reply.started": "2022-05-17T15:21:43.408071Z"
    }
   },
   "outputs": [],
   "source": [
    "# Balance data set\n",
    "# Choose if you want to use images with 3 dimensions (in RGB) or the grayscale images\n",
    "# For transfer learning we need images in RGB values\n",
    "preprocessed_train_df = train_df.copy()\n",
    "test = False\n",
    "\n",
    "preprocessed_train_df = augmentData(train_df)\n",
    "    \n",
    "# dim = FindLargestDim(preprocessed_train_df)\n",
    "dim = (128,128)\n",
    "preprocessor = Preprocessor(dim, test)\n",
    "preprocessed_train_df = preprocessor(preprocessed_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:22:04.469326Z",
     "iopub.status.busy": "2022-05-17T15:22:04.468488Z",
     "iopub.status.idle": "2022-05-17T15:22:04.673650Z",
     "shell.execute_reply": "2022-05-17T15:22:04.672894Z",
     "shell.execute_reply.started": "2022-05-17T15:22:04.469277Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12188\\1300621630.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'img'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocessed_train_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'img'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocessed_train_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'img'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocessed_train_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'img'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(train_df['img']))\n",
    "print(len(preprocessed_train_df['img']))\n",
    "print(preprocessed_train_df['img'][600].shape)\n",
    "plt.imshow(preprocessed_train_df['img'][600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:22:07.586378Z",
     "iopub.status.busy": "2022-05-17T15:22:07.586044Z",
     "iopub.status.idle": "2022-05-17T15:22:07.613239Z",
     "shell.execute_reply": "2022-05-17T15:22:07.612526Z",
     "shell.execute_reply.started": "2022-05-17T15:22:07.586341Z"
    }
   },
   "outputs": [],
   "source": [
    "# checking how balanced the dataset becomes after preprocessing\n",
    "for i in range(len(preprocessed_train_df.columns)-2):\n",
    "    arr = preprocessed_train_df[preprocessed_train_df.columns[i]].to_numpy()\n",
    "    amount = np.count_nonzero(arr == 1)\n",
    "\n",
    "    print('Number of', preprocessed_train_df.columns[i], ':', amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the images need to be put in datastructures which are compatible with the CNN's used\n",
    "\n",
    "output is a so called one-hot encoding. One-hot encoding can be used when as loss the categorical-entropy wordt gebruikt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:22:10.617897Z",
     "iopub.status.busy": "2022-05-17T15:22:10.617580Z",
     "iopub.status.idle": "2022-05-17T15:22:11.930367Z",
     "shell.execute_reply": "2022-05-17T15:22:11.929522Z",
     "shell.execute_reply.started": "2022-05-17T15:22:10.617862Z"
    }
   },
   "outputs": [],
   "source": [
    "SIZE_IMG = dim[0]\n",
    "\n",
    "y = preprocessed_train_df[['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']]\n",
    "train_y = y.to_numpy()\n",
    "print(train_y)\n",
    "\n",
    "# reshape images \n",
    "# input images should have a shape [batch_size, img_height, img_width, number_of_channels]\n",
    "numberOfIm = len(preprocessed_train_df[\"img\"])\n",
    "dimIm = 3\n",
    "    \n",
    "train_x = np.array(np.zeros([numberOfIm, SIZE_IMG, SIZE_IMG, dimIm]))\n",
    "for i in range(numberOfIm):\n",
    "    Im = preprocessed_train_df[\"img\"][i]\n",
    "    A = np.asarray(Im).reshape(SIZE_IMG,SIZE_IMG,dimIm)\n",
    "    train_x[i,:,:,:] = A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same preprocess procedure for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:22:13.574465Z",
     "iopub.status.busy": "2022-05-17T15:22:13.573856Z",
     "iopub.status.idle": "2022-05-17T15:22:15.474352Z",
     "shell.execute_reply": "2022-05-17T15:22:15.473548Z",
     "shell.execute_reply.started": "2022-05-17T15:22:13.574424Z"
    }
   },
   "outputs": [],
   "source": [
    "# same preprocessing procedure for the test data\n",
    "test = True\n",
    "\n",
    "preprocessed_test_df = test_df.copy()\n",
    "# dim = FindLargestDim(test_df)\n",
    "dim = (128,128)\n",
    "preprocessor = Preprocessor(dim, test)\n",
    "preprocessed_test_df = preprocessor(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:22:22.536513Z",
     "iopub.status.busy": "2022-05-17T15:22:22.536239Z",
     "iopub.status.idle": "2022-05-17T15:22:22.743802Z",
     "shell.execute_reply": "2022-05-17T15:22:22.743061Z",
     "shell.execute_reply.started": "2022-05-17T15:22:22.536484Z"
    }
   },
   "outputs": [],
   "source": [
    "print(preprocessed_test_df['img'][2].shape)\n",
    "print(len(preprocessed_test_df['img']))\n",
    "plt.imshow(preprocessed_test_df['img'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:22:25.185716Z",
     "iopub.status.busy": "2022-05-17T15:22:25.184933Z",
     "iopub.status.idle": "2022-05-17T15:22:25.616059Z",
     "shell.execute_reply": "2022-05-17T15:22:25.615259Z",
     "shell.execute_reply.started": "2022-05-17T15:22:25.185672Z"
    }
   },
   "outputs": [],
   "source": [
    "# reshape images \n",
    "# input images should have a shape [batch_size, img_height, img_width, number_of_channels]\n",
    "numberOfIm = len(preprocessed_test_df[\"img\"])\n",
    "test = np.array(np.zeros([numberOfIm, SIZE_IMG, SIZE_IMG, dimIm]))\n",
    "for i in range(numberOfIm):\n",
    "    Im = preprocessed_test_df[\"img\"][i]\n",
    "    A = np.asarray(Im).reshape(SIZE_IMG,SIZE_IMG,dimIm)\n",
    "    test[i,:,:,:] = A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:22:27.812519Z",
     "iopub.status.busy": "2022-05-17T15:22:27.811751Z",
     "iopub.status.idle": "2022-05-17T15:22:27.818253Z",
     "shell.execute_reply": "2022-05-17T15:22:27.817183Z",
     "shell.execute_reply.started": "2022-05-17T15:22:27.812478Z"
    }
   },
   "outputs": [],
   "source": [
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.196641,
     "end_time": "2022-04-12T14:49:03.240824",
     "exception": false,
     "start_time": "2022-04-12T14:49:03.044183",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Image classification\n",
    "The goal here is simple: implement a classification CNN and train it to recognise all 20 classes (and/or background) using the training set and compete on the test set (by filling in the classification columns in the test dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:22:32.391932Z",
     "iopub.status.busy": "2022-05-17T15:22:32.391230Z",
     "iopub.status.idle": "2022-05-17T15:23:11.211269Z",
     "shell.execute_reply": "2022-05-17T15:23:11.210512Z",
     "shell.execute_reply.started": "2022-05-17T15:22:32.391884Z"
    },
    "papermill": {
     "duration": 3.702597,
     "end_time": "2022-04-12T14:49:07.13902",
     "exception": false,
     "start_time": "2022-04-12T14:49:03.436423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RandomClassificationModel:\n",
    "    \"\"\"\n",
    "    Random classification model: \n",
    "        - generates random labels for the inputs based on the class distribution observed during training\n",
    "        - assumes an input can have multiple labels\n",
    "    \"\"\"\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Adjusts the class ratio variable to the one observed in y. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: list of arrays - n x (height x width x 3)\n",
    "        y: list of arrays - n x (nb_classes)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "        self.distribution = np.mean(y, axis=0)\n",
    "        print(\"Setting class distribution to:\\n{}\".format(\"\\n\".join(f\"{label}: {p}\" for label, p in zip(labels, self.distribution))))\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predicts for each input a label.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X: list of arrays - n x (height x width x 3)\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        y_pred: list of arrays - n x (nb_classes)\n",
    "        \"\"\"\n",
    "        np.random.seed(0)\n",
    "        return [np.array([int(np.random.rand() < p) for p in self.distribution]) for _ in X]\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        return self.predict(X)\n",
    "    \n",
    "randomModel = RandomClassificationModel()\n",
    "randomModel.fit(train_df[\"img\"], train_df[labels])\n",
    "test_df.loc[:, labels] = randomModel.predict(test_df[\"img\"])\n",
    "test_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Image classification from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1\n",
    "\n",
    "The goal here is simple: implement a classification CNN and train it to recognise all 20 classes (and/or background) using the training set and compete on the test set (by filling in the classification columns in the test dataframe).\n",
    "\n",
    "https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:23:11.213473Z",
     "iopub.status.busy": "2022-05-17T15:23:11.213034Z",
     "iopub.status.idle": "2022-05-17T15:23:11.374890Z",
     "shell.execute_reply": "2022-05-17T15:23:11.374105Z",
     "shell.execute_reply.started": "2022-05-17T15:23:11.213430Z"
    }
   },
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import matplotlib.image as mpimg\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:27:59.339038Z",
     "iopub.status.busy": "2022-05-17T15:27:59.338424Z",
     "iopub.status.idle": "2022-05-17T15:27:59.430494Z",
     "shell.execute_reply": "2022-05-17T15:27:59.428902Z",
     "shell.execute_reply.started": "2022-05-17T15:27:59.338994Z"
    }
   },
   "outputs": [],
   "source": [
    "# model that was proposed in the blog\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32,(3,3),activation = \"relu\" , input_shape = (128,128,3)) ,\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32,(3,3),activation = \"relu\") ,  \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation = \"relu\") ,  \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # added\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation = \"relu\") ,  \n",
    "    tf.keras.layers.AveragePooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Flatten(), \n",
    "    tf.keras.layers.Dense(64,activation=\"relu\"),      #Adding the Hidden layer\n",
    "    tf.keras.layers.Dropout(0.2, seed = 2019),\n",
    "    tf.keras.layers.Dense(20,activation = \"sigmoid\")   #Adding the Output Layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2\n",
    "## This is the first model we tried, the predictions are not that good. After 1 epoch overfit\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16,(3,3),activation = \"relu\" , input_shape = (128,128,3)) ,\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32,(3,3),activation = \"relu\") ,  \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64,(3,3),activation = \"relu\") ,  \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128,(3,3),activation = \"relu\"),  \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(), \n",
    "    tf.keras.layers.Dense(550,activation=\"relu\"),      #Adding the Hidden layer\n",
    "    tf.keras.layers.Dropout(0.1,seed = 2019),\n",
    "    #tf.keras.layers.Dense(400,activation =\"relu\"),\n",
    "    #tf.keras.layers.Dropout(0.3,seed = 2019),\n",
    "    #tf.keras.layers.Dense(300,activation=\"relu\"),\n",
    "    #tf.keras.layers.Dropout(0.4,seed = 2019),\n",
    "    #tf.keras.layers.Dense(200,activation =\"relu\"),\n",
    "    #tf.keras.layers.Dropout(0.2,seed = 2019),\n",
    "    tf.keras.layers.Dense(20,activation = \"sigmoid\")   #Adding the Output Layer: kleine getalletjes want absolute kansen (softmaxgeeft relatieve kansen, dus is niet dat hij heel onaccuraat is)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:28:02.613321Z",
     "iopub.status.busy": "2022-05-17T15:28:02.612670Z",
     "iopub.status.idle": "2022-05-17T15:28:02.625692Z",
     "shell.execute_reply": "2022-05-17T15:28:02.624524Z",
     "shell.execute_reply.started": "2022-05-17T15:28:02.613275Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[COPYRIGHT] So far, we've seen RMSProp and Momentum take contrasting approaches. While momentum accelerates our search in direction of minima, RMSProp impedes our search in direction of oscillations. Adam or Adaptive Moment Optimization algorithms combines the heuristics of both Momentum and RMSProp.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:28:58.903389Z",
     "iopub.status.busy": "2022-05-17T15:28:58.902720Z",
     "iopub.status.idle": "2022-05-17T15:28:58.917890Z",
     "shell.execute_reply": "2022-05-17T15:28:58.917116Z",
     "shell.execute_reply.started": "2022-05-17T15:28:58.903344Z"
    }
   },
   "outputs": [],
   "source": [
    "# binary cross entropy: multiple labels per photo 1 000.  11000\n",
    "from tensorflow.keras.optimizers import RMSprop,SGD,Adam\n",
    "\n",
    "# TODO: overfit wrsch: binary of cross: want hoe bepaal je accuracty en loss nu? want multilabel nu, \n",
    "# maar kijkt hij naar 1 of 2 values nu?\n",
    "# probleem: val los wordt hoger ipv lager$\n",
    "\n",
    "# adam: lr groot -> verklein. 0.1 -> 0.001 -> 0.000001\n",
    "# wat is rmsprop -> opzoeken (adam goed)\n",
    "adam = Adam(lr=0.01)\n",
    "\n",
    "model.compile(#optimizer='rmsprop',\n",
    "              optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:29:44.977348Z",
     "iopub.status.busy": "2022-05-17T15:29:44.977037Z",
     "iopub.status.idle": "2022-05-17T15:29:53.677926Z",
     "shell.execute_reply": "2022-05-17T15:29:53.677055Z",
     "shell.execute_reply.started": "2022-05-17T15:29:44.977318Z"
    }
   },
   "outputs": [],
   "source": [
    "# This callback will stop the training when there is no improvement in\n",
    "# the loss for three consecutive epochs.\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "checkpoint_filepath = 'checkpoint.h5'\n",
    "# Model weights are saved at the end of every epoch, if it's the best seen so far.\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "\n",
    "history = model.fit(train_x, train_y, validation_split=0.2, epochs=500, batch_size=32, verbose=1, callbacks=[callback, model_checkpoint_callback])\n",
    "\n",
    "# The model weights (that are considered the best) are loaded into the model.\n",
    "model.load_weights(checkpoint_filepath)\n",
    "\n",
    "model.save('model_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:30:06.655686Z",
     "iopub.status.busy": "2022-05-17T15:30:06.655399Z",
     "iopub.status.idle": "2022-05-17T15:30:27.115640Z",
     "shell.execute_reply": "2022-05-17T15:30:27.114900Z",
     "shell.execute_reply.started": "2022-05-17T15:30:06.655653Z"
    }
   },
   "outputs": [],
   "source": [
    "# plotting the accuracy and loss functions\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])   # Terug toeveogen wanneer validatieset hebben\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import keras\n",
    "#model = keras.models.load_model('ModelFromScracth.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:37:43.049419Z",
     "iopub.status.busy": "2022-05-17T15:37:43.048548Z",
     "iopub.status.idle": "2022-05-17T15:37:43.514430Z",
     "shell.execute_reply": "2022-05-17T15:37:43.513568Z",
     "shell.execute_reply.started": "2022-05-17T15:37:43.049337Z"
    }
   },
   "outputs": [],
   "source": [
    "# make a prediction on the test set\n",
    "yhat = model.predict(test)\n",
    "print(yhat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:38:15.278090Z",
     "iopub.status.busy": "2022-05-17T15:38:15.277744Z",
     "iopub.status.idle": "2022-05-17T15:38:15.283069Z",
     "shell.execute_reply": "2022-05-17T15:38:15.282320Z",
     "shell.execute_reply.started": "2022-05-17T15:38:15.278054Z"
    }
   },
   "outputs": [],
   "source": [
    "# choose threshold to convert to zero's and ones\n",
    "yhat = yhat > 0.1\n",
    "yhat = yhat.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:38:17.075125Z",
     "iopub.status.busy": "2022-05-17T15:38:17.074838Z",
     "iopub.status.idle": "2022-05-17T15:38:17.126499Z",
     "shell.execute_reply": "2022-05-17T15:38:17.125754Z",
     "shell.execute_reply.started": "2022-05-17T15:38:17.075088Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:38:33.784504Z",
     "iopub.status.busy": "2022-05-17T15:38:33.783859Z",
     "iopub.status.idle": "2022-05-17T15:38:34.005800Z",
     "shell.execute_reply": "2022-05-17T15:38:34.005063Z",
     "shell.execute_reply.started": "2022-05-17T15:38:33.784463Z"
    }
   },
   "outputs": [],
   "source": [
    "## Testing with 1 image\n",
    "plt.imshow(test_df[\"img\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:30:44.081557Z",
     "iopub.status.busy": "2022-05-17T15:30:44.081267Z",
     "iopub.status.idle": "2022-05-17T15:30:44.158932Z",
     "shell.execute_reply": "2022-05-17T15:30:44.158120Z",
     "shell.execute_reply.started": "2022-05-17T15:30:44.081525Z"
    }
   },
   "outputs": [],
   "source": [
    "testImage = test[1,:,:,:]\n",
    "pred = model.predict(testImage.reshape(1,128,128,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:31:55.760831Z",
     "iopub.status.busy": "2022-05-17T15:31:55.760525Z",
     "iopub.status.idle": "2022-05-17T15:31:55.772509Z",
     "shell.execute_reply": "2022-05-17T15:31:55.771684Z",
     "shell.execute_reply.started": "2022-05-17T15:31:55.760786Z"
    }
   },
   "outputs": [],
   "source": [
    "print(pred)\n",
    "print(np.argmax(pred))\n",
    "top = np.argsort(pred[0])[:-4:-1]\n",
    "print(top)\n",
    "for i in range(len(top)):\n",
    "    index = top[i]\n",
    "    print(train_df.columns[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:31:57.853146Z",
     "iopub.status.busy": "2022-05-17T15:31:57.852072Z",
     "iopub.status.idle": "2022-05-17T15:31:58.065467Z",
     "shell.execute_reply": "2022-05-17T15:31:58.064722Z",
     "shell.execute_reply.started": "2022-05-17T15:31:57.853085Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(test_df[\"img\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:32:11.934766Z",
     "iopub.status.busy": "2022-05-17T15:32:11.934472Z",
     "iopub.status.idle": "2022-05-17T15:32:12.306542Z",
     "shell.execute_reply": "2022-05-17T15:32:12.305731Z",
     "shell.execute_reply.started": "2022-05-17T15:32:11.934734Z"
    }
   },
   "outputs": [],
   "source": [
    "testImage2 = test[2,:,:,:]\n",
    "pred = model.predict(testImage2.reshape(1,128,128,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:32:14.529427Z",
     "iopub.status.busy": "2022-05-17T15:32:14.528724Z",
     "iopub.status.idle": "2022-05-17T15:32:14.537727Z",
     "shell.execute_reply": "2022-05-17T15:32:14.536861Z",
     "shell.execute_reply.started": "2022-05-17T15:32:14.529386Z"
    }
   },
   "outputs": [],
   "source": [
    "print(pred)\n",
    "print(np.argmax(pred))\n",
    "top = np.argsort(pred)[:-4:-1]\n",
    "print(top)\n",
    "for i in range(len(top)):\n",
    "    index = top[i]\n",
    "    print(train_df.columns[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:32:32.234422Z",
     "iopub.status.busy": "2022-05-17T15:32:32.233700Z",
     "iopub.status.idle": "2022-05-17T15:32:32.449384Z",
     "shell.execute_reply": "2022-05-17T15:32:32.448710Z",
     "shell.execute_reply.started": "2022-05-17T15:32:32.234376Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(test_df[\"img\"][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:32:46.809402Z",
     "iopub.status.busy": "2022-05-17T15:32:46.809092Z",
     "iopub.status.idle": "2022-05-17T15:32:46.861469Z",
     "shell.execute_reply": "2022-05-17T15:32:46.860592Z",
     "shell.execute_reply.started": "2022-05-17T15:32:46.809369Z"
    }
   },
   "outputs": [],
   "source": [
    "testImage3 = test[3,:,:,:]\n",
    "pred = model.predict(testImage2.reshape(1,128,128,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:33:06.914507Z",
     "iopub.status.busy": "2022-05-17T15:33:06.914190Z",
     "iopub.status.idle": "2022-05-17T15:33:06.922316Z",
     "shell.execute_reply": "2022-05-17T15:33:06.921389Z",
     "shell.execute_reply.started": "2022-05-17T15:33:06.914475Z"
    }
   },
   "outputs": [],
   "source": [
    "print(pred)\n",
    "print(np.argmax(pred))\n",
    "top = np.argsort(pred[0])[:-4:-1]\n",
    "print(top)\n",
    "for i in range(len(top)):\n",
    "    index = top[i]\n",
    "    print(train_df.columns[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Image classification using a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageai.Detection import ObjectDetection\n",
    "import os\n",
    "\n",
    "execution_path = os.getcwd()\n",
    "\n",
    "detector = ObjectDetection()\n",
    "detector.setModelTypeAsRetinaNet()\n",
    "detector.setModelPath( os.path.join(execution_path , \"resnet50_coco_best_v2.0.1.h5\"))\n",
    "detector.loadModel()\n",
    "custom_objects = detector.CustomObjects(cell_phone=True,tv=True)\n",
    "detections = detector.detectCustomObjectsFromImage(custom_objects=custom_objects,input_image=os.path.join(execution_path , \"Living room picture 4.png\"), output_image_path=os.path.join(execution_path , \"Living room picture 4_new.jpg\"),display_percentage_probability=False)\n",
    "# detector.loadModel(detection_speed=\"fast\")\n",
    "for eachObject in detections:\n",
    "    print(eachObject[\"name\"] , \" : \" , eachObject[\"percentage_probability\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom_objects = retinanet.custom_objects.copy()\n",
    "#custom_objects.update(keras_resnet.custom_objects)\n",
    "\n",
    "#testmodel = keras.models.load_model('resnet50_coco_best_v2.0.1.h5', custom_objects=['{'person': \"person\"}'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using ai net\n",
    "from imageai.Detection import ObjectDetection\n",
    "import os\n",
    "\n",
    "execution_path = os.getcwd()\n",
    "\n",
    "detector = ObjectDetection()\n",
    "detector.setModelTypeAsRetinaNet()\n",
    "detector.setModelPath( os.path.join(execution_path , \"resnet50_coco_best_v2.0.1.h5\"))\n",
    "detector.loadModel()\n",
    "#custom_objects = detector.CustomObjects(person=True, car=False)\n",
    "#detections = detector.detectCustomObjectsFromImage(input_image=os.path.join(execution_path , \"image.png\"), output_image_path=os.path.join(execution_path , \"image_new.png\"), custom_objects=custom_objects, minimum_percentage_probability=65)\n",
    "\n",
    "\n",
    "#for eachObject in detections:\n",
    "#   print(eachObject[\"name\"] + \" : \" + eachObject[\"percentage_probability\"] )\n",
    "#   print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"image_new.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Image classification with transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T14:49:54.394941Z",
     "iopub.status.busy": "2022-05-17T14:49:54.394374Z",
     "iopub.status.idle": "2022-05-17T14:49:54.78421Z",
     "shell.execute_reply": "2022-05-17T14:49:54.783079Z",
     "shell.execute_reply.started": "2022-05-17T14:49:54.394891Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications import ResNet101\n",
    "from tensorflow.keras.models import Model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T14:49:54.786586Z",
     "iopub.status.busy": "2022-05-17T14:49:54.786201Z",
     "iopub.status.idle": "2022-05-17T14:49:59.576427Z",
     "shell.execute_reply": "2022-05-17T14:49:59.575309Z",
     "shell.execute_reply.started": "2022-05-17T14:49:54.78654Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "K.set_learning_phase(0)\n",
    "\n",
    "numClasses = 20\n",
    "\n",
    "base_model = ResNet101(weights=\"imagenet\", include_top=False, pooling='max', input_shape=(128, 128, 3))\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "K.set_learning_phase(1)\n",
    "\n",
    "top_model = Sequential()\n",
    "#vgg16 = tf.keras.applications.vgg16\n",
    "#transferModel.add(vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(500, 500, 3))) -> kernel dies\n",
    "#transferModel.add(ResNet50(weights=\"imagenet\", include_top=False, pooling='max', input_shape=(500, 500, 3)))\n",
    "top_model.add(Flatten())\n",
    "top_model.add(BatchNormalization(renorm=True))\n",
    "top_model.add(Dense(512, activation='relu'))\n",
    "top_model.add(Dropout(0.1))\n",
    "# top_model.add(Dense(216, activation='relu'))\n",
    "top_model.add(Dense(numClasses, activation='sigmoid'))\n",
    "#transferModel.layers[0].trainable = False\n",
    "\n",
    "transferModel = Model(base_model.input, top_model(base_model.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T14:45:29.311629Z",
     "iopub.status.busy": "2022-05-17T14:45:29.311331Z",
     "iopub.status.idle": "2022-05-17T14:45:29.316796Z",
     "shell.execute_reply": "2022-05-17T14:45:29.315737Z",
     "shell.execute_reply.started": "2022-05-17T14:45:29.311596Z"
    }
   },
   "outputs": [],
   "source": [
    "# transferModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T14:50:12.228584Z",
     "iopub.status.busy": "2022-05-17T14:50:12.228012Z",
     "iopub.status.idle": "2022-05-17T14:50:12.256123Z",
     "shell.execute_reply": "2022-05-17T14:50:12.254981Z",
     "shell.execute_reply.started": "2022-05-17T14:50:12.228545Z"
    }
   },
   "outputs": [],
   "source": [
    "adam=tf.keras.optimizers.Adam(lr=0.001)\n",
    "transferModel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T14:50:59.546649Z",
     "iopub.status.busy": "2022-05-17T14:50:59.546308Z",
     "iopub.status.idle": "2022-05-17T14:51:01.516099Z",
     "shell.execute_reply": "2022-05-17T14:51:01.514992Z",
     "shell.execute_reply.started": "2022-05-17T14:50:59.546612Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainsplit_XC, val_XC,trainsplit_yC, val_yC = train_test_split(train_x,train_y, \n",
    "                                                   test_size=0.2, \n",
    "                                                   random_state=0\n",
    "                                                  )\n",
    "train_dataC = tf.data.Dataset.from_tensor_slices((trainsplit_XC, trainsplit_yC))\n",
    "test_dataC = tf.data.Dataset.from_tensor_slices((val_XC, val_yC))\n",
    "BATCH_SIZE = 12\n",
    "BUFFER_SIZE = 1000\n",
    "train_batchesC = train_dataC.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "train_batchesC = train_batchesC.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "test_batchesC = test_dataC.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "test_batchesC = test_batchesC.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T14:51:08.750665Z",
     "iopub.status.busy": "2022-05-17T14:51:08.749894Z",
     "iopub.status.idle": "2022-05-17T14:56:55.734298Z",
     "shell.execute_reply": "2022-05-17T14:56:55.73322Z",
     "shell.execute_reply.started": "2022-05-17T14:51:08.750626Z"
    }
   },
   "outputs": [],
   "source": [
    "history = transferModel.fit(train_batchesC,validation_data=test_batchesC,steps_per_epoch=trainsplit_XC.shape[0]//BATCH_SIZE, epochs=50,validation_steps=val_XC.shape[0]//BATCH_SIZE, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T14:57:21.217214Z",
     "iopub.status.busy": "2022-05-17T14:57:21.216343Z",
     "iopub.status.idle": "2022-05-17T14:57:21.256588Z",
     "shell.execute_reply": "2022-05-17T14:57:21.254523Z",
     "shell.execute_reply.started": "2022-05-17T14:57:21.217133Z"
    }
   },
   "outputs": [],
   "source": [
    "# plotting the accuracy and loss functions\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])   # Terug toeveogen wanneer validatieset hebben\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_df[\"img\"][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testImage = test[2,:,:,:]\n",
    "pred = transferModel.predict(testImage.reshape(1,500,500,3))\n",
    "top = np.argsort(pred)[:-4:-1]\n",
    "for i in range(len(top)):\n",
    "    index = top[i]\n",
    "    print(train_df.columns[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T14:57:54.76101Z",
     "iopub.status.busy": "2022-05-17T14:57:54.760667Z",
     "iopub.status.idle": "2022-05-17T14:57:58.333963Z",
     "shell.execute_reply": "2022-05-17T14:57:58.33282Z",
     "shell.execute_reply.started": "2022-05-17T14:57:54.760957Z"
    }
   },
   "outputs": [],
   "source": [
    "yhat = transferModel.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T14:58:00.247398Z",
     "iopub.status.busy": "2022-05-17T14:58:00.246776Z",
     "iopub.status.idle": "2022-05-17T14:58:00.252953Z",
     "shell.execute_reply": "2022-05-17T14:58:00.251655Z",
     "shell.execute_reply.started": "2022-05-17T14:58:00.247359Z"
    }
   },
   "outputs": [],
   "source": [
    "yhat = yhat > 0.1\n",
    "yhat = yhat.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.19763,
     "end_time": "2022-04-12T14:49:07.53601",
     "exception": false,
     "start_time": "2022-04-12T14:49:07.33838",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Semantic segmentation\n",
    "The goal here is to implement a segmentation CNN that labels every pixel in the image as belonging to one of the 20 classes (and/or background). Use the training set to train your CNN and compete on the test set (by filling in the segmentation column in the test dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:40:56.548511Z",
     "iopub.status.busy": "2022-05-17T15:40:56.548137Z",
     "iopub.status.idle": "2022-05-17T15:41:31.439586Z",
     "shell.execute_reply": "2022-05-17T15:41:31.438858Z",
     "shell.execute_reply.started": "2022-05-17T15:40:56.548474Z"
    },
    "papermill": {
     "duration": 11.823715,
     "end_time": "2022-04-12T14:49:19.557577",
     "exception": false,
     "start_time": "2022-04-12T14:49:07.733862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RandomSegmentationModel:\n",
    "    \"\"\"\n",
    "    Random segmentation model: \n",
    "        - generates random label maps for the inputs based on the class distributions observed during training\n",
    "        - every pixel in an input can only have one label\n",
    "    \"\"\"\n",
    "    def fit(self, X, Y):\n",
    "        \"\"\"\n",
    "        Adjusts the class ratio variable to the one observed in Y. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: list of arrays - n x (height x width x 3)\n",
    "        Y: list of arrays - n x (height x width)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "        self.distribution = np.mean([[np.sum(Y_ == i) / Y_.size for i in range(len(labels) + 1)] for Y_ in Y], axis=0)\n",
    "        print(\"Setting class distribution to:\\nbackground: {}\\n{}\".format(self.distribution[0], \"\\n\".join(f\"{label}: {p}\" for label, p in zip(labels, self.distribution[1:]))))\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predicts for each input a label map.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X: list of arrays - n x (height x width x 3)\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Y_pred: list of arrays - n x (height x width)\n",
    "        \"\"\"\n",
    "        np.random.seed(0)\n",
    "        return [np.random.choice(np.arange(len(labels) + 1), size=X_.shape[:2], p=self.distribution) for X_ in X]\n",
    "    \n",
    "    def __call__(self, X):\n",
    "        return self.predict(X)\n",
    "    \n",
    "model = RandomSegmentationModel()\n",
    "model.fit(train_df[\"img\"], train_df[\"seg\"])\n",
    "test_df.loc[:, \"seg\"] = model.predict(test_df[\"img\"])\n",
    "test_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:41:31.441601Z",
     "iopub.status.busy": "2022-05-17T15:41:31.441257Z",
     "iopub.status.idle": "2022-05-17T15:41:31.888712Z",
     "shell.execute_reply": "2022-05-17T15:41:31.887890Z",
     "shell.execute_reply.started": "2022-05-17T15:41:31.441561Z"
    }
   },
   "outputs": [],
   "source": [
    "dimImy = 1\n",
    "train_y = np.array(np.zeros([preprocessed_train_df[\"seg\"].shape[0], dim[0], dim[1], dimImy]))\n",
    "for i in range(preprocessed_train_df[\"seg\"].shape[0]):\n",
    "    Im = preprocessed_train_df[\"seg\"][i]\n",
    "    A = np.asarray(Im).reshape(dim[0],dim[1],dimImy)\n",
    "    train_y[i,:,:,:] = A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:41:31.890535Z",
     "iopub.status.busy": "2022-05-17T15:41:31.890281Z",
     "iopub.status.idle": "2022-05-17T15:41:31.896509Z",
     "shell.execute_reply": "2022-05-17T15:41:31.895689Z",
     "shell.execute_reply.started": "2022-05-17T15:41:31.890500Z"
    }
   },
   "outputs": [],
   "source": [
    "type(preprocessed_train_df[\"seg\"].shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:41:35.230124Z",
     "iopub.status.busy": "2022-05-17T15:41:35.229432Z",
     "iopub.status.idle": "2022-05-17T15:41:36.161658Z",
     "shell.execute_reply": "2022-05-17T15:41:36.160680Z",
     "shell.execute_reply.started": "2022-05-17T15:41:35.230082Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainsplit_X, val_X,trainsplit_y, val_y = train_test_split(train_x,train_y, \n",
    "                                                   test_size=0.2, \n",
    "                                                   random_state=0\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:41:36.919372Z",
     "iopub.status.busy": "2022-05-17T15:41:36.918681Z",
     "iopub.status.idle": "2022-05-17T15:41:39.094893Z",
     "shell.execute_reply": "2022-05-17T15:41:39.094006Z",
     "shell.execute_reply.started": "2022-05-17T15:41:36.919327Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((trainsplit_X, trainsplit_y))\n",
    "test_data = tf.data.Dataset.from_tensor_slices((val_X, val_y))\n",
    "BATCH_SIZE = 12\n",
    "BUFFER_SIZE = 1000\n",
    "train_batches = train_data.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "train_batches = train_batches.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "test_batches = test_data.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "test_batches = test_batches.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:41:39.097452Z",
     "iopub.status.busy": "2022-05-17T15:41:39.097014Z",
     "iopub.status.idle": "2022-05-17T15:41:39.103404Z",
     "shell.execute_reply": "2022-05-17T15:41:39.102687Z",
     "shell.execute_reply.started": "2022-05-17T15:41:39.097412Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:41:42.378583Z",
     "iopub.status.busy": "2022-05-17T15:41:42.378299Z",
     "iopub.status.idle": "2022-05-17T15:41:42.403481Z",
     "shell.execute_reply": "2022-05-17T15:41:42.402672Z",
     "shell.execute_reply.started": "2022-05-17T15:41:42.378552Z"
    }
   },
   "outputs": [],
   "source": [
    "class Unet_model:\n",
    "    def __init__(self, input_shape):\n",
    "            self.input_shape=input_shape\n",
    "            \n",
    "    def down_block(self,x,size):\n",
    "        conv = tf.keras.layers.Conv2D(size, (3, 3), kernel_initializer='he_normal',\n",
    "                                    padding='same')(x)\n",
    "        conv = tf.keras.layers.Activation('relu')(conv)\n",
    "        conv = tf.keras.layers.Dropout(0.05)(conv)\n",
    "\n",
    "        conv = tf.keras.layers.Conv2D(size, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n",
    "                                    padding='same')(conv)\n",
    "        pool = tf.keras.layers.MaxPooling2D((2, 2))(conv)\n",
    "        return pool,conv\n",
    "\n",
    "    def bottleneck(self,x,size):\n",
    "        conv = tf.keras.layers.Conv2D(size, (3, 3), kernel_initializer='he_normal',\n",
    "                                    padding='same')(x)\n",
    "        conv = tf.keras.layers.Activation('relu')(conv)\n",
    "        conv = tf.keras.layers.Dropout(0.05)(conv)\n",
    "        conv = tf.keras.layers.Conv2D(size, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n",
    "                                    padding='same')(conv)\n",
    "        return conv\n",
    "\n",
    "    def up_block(self,x,y,size):\n",
    "    #     upconv = tf.keras.layers.Conv2DTranspose(size, (2, 2), strides=(2, 2), padding='same')(x)\n",
    "        upconv = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "        upconv = tf.keras.layers.concatenate([upconv, y])\n",
    "        conv = tf.keras.layers.Conv2D(size, (3, 3), kernel_initializer='he_normal',\n",
    "                                    padding='same')(upconv)\n",
    "        conv = tf.keras.layers.Activation('relu')(conv)\n",
    "        conv = tf.keras.layers.Dropout(0.05)(conv)\n",
    "        conv = tf.keras.layers.Conv2D(size, (3, 3), activation=tf.keras.activations.relu, kernel_initializer='he_normal',\n",
    "                                    padding='same')(conv)\n",
    "        return conv\n",
    "\n",
    "    def Model(self):\n",
    "        \"\"\"\n",
    "        Function to build the UNet model that was used for the own model in image segemntation\n",
    "        We experimented with both dropout and batchnormalization\n",
    "        In some experiments the dropout and or batchnormalization was removed or tweaked\n",
    "        \"\"\"\n",
    "        inputs = Input(self.input_shape)\n",
    "\n",
    "        pool1,conv1 = self.down_block(inputs,16)\n",
    "        pool2,conv2 = self.down_block(pool1,32)\n",
    "        pool3,conv3 = self.down_block(pool2,64)\n",
    "        pool4,conv4 = self.down_block(pool3,128)\n",
    "        pool5,conv5 = self.down_block(pool4,256)\n",
    "\n",
    "        conv6 = self.bottleneck(pool5,512)\n",
    "\n",
    "        conv7 = self.up_block(conv6,conv5,256)\n",
    "        conv8 = self.up_block(conv7,conv4,128)\n",
    "        conv9 = self.up_block(conv8,conv3,64)\n",
    "        conv10 = self.up_block(conv9,conv2,32)\n",
    "        conv11 = self.up_block(conv10,conv1,16)\n",
    "\n",
    "        outputs = tf.keras.layers.Conv2D(21, (1, 1), activation='sigmoid')(conv11)\n",
    "\n",
    "        self.model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "        self.model.compile(optimizer=tf.keras.optimizers.Adam(\n",
    "            learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "                name='Adam'),\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                      metrics=['acc'])\n",
    "#         self.model.summary()\n",
    "        return self.model\n",
    "\n",
    "    def fit(self,train_dataset,steps_train,Epochs,val_dataset=None,steps_val=None):\n",
    "        self.model.fit_generator(train_dataset,validation_data=val_dataset,steps_per_epoch=steps_train,validation_steps = steps_val, epochs=Epochs)\n",
    "        \n",
    "    def predict(self,test_image):\n",
    "        x,y,_ = test_image.shape\n",
    "        test_image = np.array(test_image)\n",
    "        test_im = cv2.resize(test_image, (128,128), interpolation = cv2.INTER_NEAREST)\n",
    "        test_im = test_im / 255.0\n",
    "        test_im = cv2.GaussianBlur(test_im,(5,5),cv2.BORDER_DEFAULT)\n",
    "        trst_im = tf.convert_to_tensor(test_im)\n",
    "        test_im = tf.expand_dims(test_im, axis=0)\n",
    "        pr = self.model.predict(test_im)\n",
    "        pred_mask = tf.argmax(pr[0], axis=-1)\n",
    "        pred_mask = pred_mask[..., tf.newaxis]\n",
    "        pred_mask = cv2.resize(np.array(pred_mask), (y,x), interpolation = cv2.INTER_NEAREST)\n",
    "        return pred_mask\n",
    "    \n",
    "    def __call__(self):\n",
    "        return self.Model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T15:53:07.725406Z",
     "iopub.status.busy": "2022-05-17T15:53:07.724944Z",
     "iopub.status.idle": "2022-05-17T16:02:32.145016Z",
     "shell.execute_reply": "2022-05-17T16:02:32.144013Z",
     "shell.execute_reply.started": "2022-05-17T15:53:07.725370Z"
    }
   },
   "outputs": [],
   "source": [
    "input_shape = (dim[0], dim[1], 3)\n",
    "Unet =  Unet_model(input_shape)\n",
    "model_U = Unet()\n",
    "Unet.fit(train_batches,trainsplit_X.shape[0]//BATCH_SIZE, 100,test_batches,val_X.shape[0]//BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T16:05:26.472238Z",
     "iopub.status.busy": "2022-05-17T16:05:26.471374Z",
     "iopub.status.idle": "2022-05-17T16:05:27.051431Z",
     "shell.execute_reply": "2022-05-17T16:05:27.050687Z",
     "shell.execute_reply.started": "2022-05-17T16:05:26.472190Z"
    }
   },
   "outputs": [],
   "source": [
    "P=Unet.predict(train_df[\"img\"][2])\n",
    "fig, axs = plt.subplots(1,3)\n",
    "axs[0].imshow(train_df[\"img\"][2])\n",
    "axs[1].imshow(train_df[\"seg\"][2])\n",
    "axs[2].imshow(P)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T16:05:29.600441Z",
     "iopub.status.busy": "2022-05-17T16:05:29.599681Z",
     "iopub.status.idle": "2022-05-17T16:06:03.697890Z",
     "shell.execute_reply": "2022-05-17T16:06:03.697102Z",
     "shell.execute_reply.started": "2022-05-17T16:05:29.600399Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(test_df[\"img\"].shape[0]):\n",
    "    P=Unet.predict(test_df[\"img\"][i])\n",
    "    test_df[\"seg\"][i]=P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T16:06:03.699945Z",
     "iopub.status.busy": "2022-05-17T16:06:03.699667Z",
     "iopub.status.idle": "2022-05-17T16:06:03.747399Z",
     "shell.execute_reply": "2022-05-17T16:06:03.746434Z",
     "shell.execute_reply.started": "2022-05-17T16:06:03.699908Z"
    }
   },
   "outputs": [],
   "source": [
    "print(test_df[\"seg\"][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.196901,
     "end_time": "2022-04-12T14:49:19.951018",
     "exception": false,
     "start_time": "2022-04-12T14:49:19.754117",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Submit to competition\n",
    "You don't need to edit this section. Just use it at the right position in the notebook. See the definition of this function in Sect. 1.3 for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T16:10:02.076978Z",
     "iopub.status.busy": "2022-05-17T16:10:02.075892Z",
     "iopub.status.idle": "2022-05-17T16:10:33.498210Z",
     "shell.execute_reply": "2022-05-17T16:10:33.497471Z",
     "shell.execute_reply.started": "2022-05-17T16:10:02.076928Z"
    }
   },
   "outputs": [],
   "source": [
    "# export solutions to good format\n",
    "test_df.loc[:, labels] = yhat\n",
    "test_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-17T16:10:33.500360Z",
     "iopub.status.busy": "2022-05-17T16:10:33.500088Z",
     "iopub.status.idle": "2022-05-17T16:10:34.709635Z",
     "shell.execute_reply": "2022-05-17T16:10:34.708786Z",
     "shell.execute_reply.started": "2022-05-17T16:10:33.500323Z"
    },
    "papermill": {
     "duration": 81.176133,
     "end_time": "2022-04-12T14:50:41.324425",
     "exception": false,
     "start_time": "2022-04-12T14:49:20.148292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_submission(test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.197466,
     "end_time": "2022-04-12T14:50:41.721228",
     "exception": false,
     "start_time": "2022-04-12T14:50:41.523762",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Adversarial attack\n",
    "For this part, your goal is to fool your classification and/or segmentation CNN, using an *adversarial attack*. More specifically, the goal is build a CNN to perturb test images in a way that (i) they look unperturbed to humans; but (ii) the CNN classifies/segments these images in line with the perturbations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fast Gradient Sign Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import MSE\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image_adversary(model, image, label, eps=2 / 255.0):\n",
    "    # cast the image\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    # record our gradients\n",
    "    with tf.GradientTape() as tape:\n",
    "        # explicitly indicate that our image should be tacked for gradient updates\n",
    "        tape.watch(image)\n",
    "        # use our model to make predictions on the input image and then compute the loss   \n",
    "        pred = model(tf.reshape(image, (1,500,500,3)))\n",
    "        loss = MSE(label, pred)\n",
    "    # calculate the gradients of loss with respect to the image, then compute the sign of the gradient\n",
    "    gradient = tape.gradient(loss, image)\n",
    "    signedGrad = tf.sign(gradient)\n",
    "    # construct the image adversary\n",
    "    adversary = (image + (signedGrad * eps)).numpy()\n",
    "    # return the image adversary to the calling function\n",
    "    return adversary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_df[\"img\"][4])\n",
    "top = np.argsort(train_y[4])[:-2:-1]\n",
    "print(train_y[4])\n",
    "for i in range(len(top)):\n",
    "    index = top[i]\n",
    "    print(train_df.columns[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testImage = train_x[4,:,:,:]\n",
    "pred = transferModel.predict(testImage.reshape(1,500,500,3))\n",
    "top = np.argsort(pred[0])[:-2:-1]\n",
    "for i in range(len(top)):\n",
    "    index = top[i]\n",
    "    print(train_df.columns[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversary = generate_image_adversary(transferModel, testImage, train_y[10], eps=0.1)\n",
    "plt.imshow(adversary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predAdv = transferModel.predict(tf.reshape(adversary, (1,500,500,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = np.argsort(predAdv[0])[:-2:-1]\n",
    "for i in range(len(top)):\n",
    "    index = top[i]\n",
    "    print(train_df.columns[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.195695,
     "end_time": "2022-04-12T14:50:42.117581",
     "exception": false,
     "start_time": "2022-04-12T14:50:41.921886",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Discussion\n",
    "Finally, take some time to reflect on what you have learned during this assignment. Reflect and produce an overall discussion with links to the lectures and \"real world\" computer vision."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
